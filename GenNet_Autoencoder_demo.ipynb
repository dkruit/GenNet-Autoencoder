{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenNet Autoencoder demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4ZdNysE6ZDgINljxDxXID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkruit/GenNet-Autoencoder/blob/main/GenNet_Autoencoder_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOL_1JcDSnYX"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d22SvEk8F1rm"
      },
      "source": [
        "# Import required packages\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "from tensorflow.python.keras import activations\n",
        "from tensorflow.python.keras import backend as Kb\n",
        "from tensorflow.python.keras import constraints\n",
        "from tensorflow.python.keras import initializers\n",
        "from tensorflow.python.keras import regularizers\n",
        "from tensorflow.python.keras.engine.base_layer import Layer\n",
        "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from tensorflow.python.keras.utils import tf_utils\n",
        "from tensorflow.python.util.tf_export import keras_export"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96E3Lpz6S02S"
      },
      "source": [
        "# Functions to generate dataset and mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vHY7ZveGwBT",
        "outputId": "1819e74d-5245-45bf-f0a5-a513fea8d8e8"
      },
      "source": [
        "def generate_dataset(num_patients=100, num_features=100, ld_blocks=10, n_haplotypes=2, \n",
        "                     p=0.3, random_seed=8769879, shuffle=False, verbose=False):\n",
        "    \"\"\"\n",
        "    This function creates an dataset with artificial genomes with a simplified\n",
        "    form of linkage disequilibrium.\n",
        "    \"\"\"\n",
        "    print(\"\\nCreating dataset with genotype size\", num_features, \"and\", num_patients, \"individuals.\")\n",
        "    np.random.seed(random_seed)\n",
        "    \n",
        "    dataset = np.empty([num_patients, num_features])\n",
        "    dataset[:] = np.nan  # Makes it more clear which values are filled when printing the dataset\n",
        "    \n",
        "    # Generate indices where LD-blocks start and finish\n",
        "    blocks = np.linspace(0, num_features, ld_blocks+1, dtype=np.int32)\n",
        "    \n",
        "    if verbose:\n",
        "        print('LD blocks start/end at SNP with index ', blocks)\n",
        "    \n",
        "    # Fill the LD-blocks one by one\n",
        "    for i in range(ld_blocks):\n",
        "        n_in_block = blocks[i+1] - blocks[i]\n",
        "        genotypes = []\n",
        "\n",
        "        # Generate haplotypes for this LD block\n",
        "        for j in range(n_haplotypes):\n",
        "            genotypes.append(np.random.binomial(2, p, n_in_block))\n",
        "        \n",
        "        # Randomly divide patients in n_haplotypes subsets of equal size\n",
        "        patient_subsets = np.random.permutation(np.arange(0, num_patients)).reshape(n_haplotypes,num_patients//n_haplotypes)\n",
        "        \n",
        "        # Fill dataset\n",
        "        for j in range(n_haplotypes):\n",
        "            dataset[patient_subsets[j], blocks[i]:blocks[i+1]] = genotypes[j]\n",
        "        \n",
        "        if verbose:\n",
        "          print('\\nDataset after %d out of %d LD blocks are generated:' % (i+1, ld_blocks))\n",
        "          print(dataset)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = np.random.permutation(dataset.T).T\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "# Small 18x4 dataset to show how the dataset is filled.\n",
        "_ = generate_dataset(num_features=18, num_patients=4, ld_blocks=3, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating dataset with genotype size 18 and 4 individuals.\n",
            "LD blocks start/ end at SNP with index  [ 0  6 12 18]\n",
            "\n",
            "Dataset after 1 out of 3 LD blocks are generated:\n",
            "[[ 2.  0.  1.  0.  2.  1. nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [ 2.  0.  1.  0.  2.  1. nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [ 0.  0.  0.  1.  1.  1. nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [ 0.  0.  0.  1.  1.  1. nan nan nan nan nan nan nan nan nan nan nan nan]]\n",
            "\n",
            "Dataset after 2 out of 3 LD blocks are generated:\n",
            "[[ 2.  0.  1.  0.  2.  1.  1.  1.  0.  1.  0.  1. nan nan nan nan nan nan]\n",
            " [ 2.  0.  1.  0.  2.  1.  1.  1.  0.  1.  0.  1. nan nan nan nan nan nan]\n",
            " [ 0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0. nan nan nan nan nan nan]\n",
            " [ 0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0. nan nan nan nan nan nan]]\n",
            "\n",
            "Dataset after 3 out of 3 LD blocks are generated:\n",
            "[[2. 0. 1. 0. 2. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
            " [2. 0. 1. 0. 2. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUhPvJfjOwdM"
      },
      "source": [
        "# Generate mask file\n",
        "def generate_mask(input_size, output_size):\n",
        "    '''\n",
        "    The Autoencoder needs a mask to specify which SNPs in the inputs layer need \n",
        "    to be connected to which genes in the output layer.\n",
        "\n",
        "    This function creates a mask which connects each gene to \n",
        "    input_size / output_size SNPs. This number is sometimes rounded up and\n",
        "    sometimes rounded down in order to connect each SNP to one gene.\n",
        "    \n",
        "    Example with 8 SNPs and 4 genes:\n",
        "                output\n",
        "               1 2 3 4 \n",
        "     input 1 | 1 0 0 0 |\n",
        "     input 2 | 1 0 0 0 |\n",
        "     input 3 | 0 1 0 0 |\n",
        "     input 4 | 0 1 0 0 |\n",
        "     input 5 | 0 0 1 0 |\n",
        "     input 6 | 0 0 1 0 |\n",
        "     input 7 | 0 0 0 1 |\n",
        "     input 8 | 0 0 0 1 |\n",
        "\n",
        "    The mask should be stored in a .npz sparse matrix file. \n",
        "    '''\n",
        "    mask_d = np.zeros((inputsize, output_size), np.bool)\n",
        "    start_neuron = np.round(np.linspace(0, input_size, output_size + 1)).astype(int)\n",
        "    for i in range(output_size):\n",
        "        mask_d[start_neuron[i]:start_neuron[i + 1], i] = True\n",
        "    mask = scipy.sparse.coo_matrix(mask_d)\n",
        "    return mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXGlpjDHSVyt"
      },
      "source": [
        "# GenNet Locally-Directed1D layer, AutoEncoder class and AWCC loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ0H6_iqRZsC"
      },
      "source": [
        "# Locally-Directed1D layer. The TensorFlow layer from the GenNet project.\n",
        "\n",
        "@keras_export('keras.layers.LocallyConnected1D')\n",
        "class LocallyDirected1D(Layer):\n",
        "    \"\"\"Locally-Directed1D layer for 1D inputs.\n",
        "    Dense layer with custom connections. The custom connections are defined by the mask input, a sparse (COO) connectivity matrix.\n",
        "    # The matrix has the shape of (N_nodes_layer_1, N_nodes_layer_2).\n",
        "    # It is a sparse matrix with zeros for no connections and ones if there is a connections. For example.\n",
        "    #             output\n",
        "    #           1 2 3 4 5\n",
        "    # input 1 | 1 0 0 0 0 |\n",
        "    # input 2 | 1 1 0 0 0 |\n",
        "    # input 3 | 0 1 0 0 0 |\n",
        "    # input 4 | 0 1 0 0 0 |\n",
        "    # input 5 | 0 0 1 0 0 |\n",
        "    # input 6 | 0 0 0 1 0 |\n",
        "    # input 7 | 0 0 0 1 0 |\n",
        "    # This connects the first two inputs (1,2) to the first neuron in the second layer.\n",
        "    # Connects input 2,3 and 4 to output neuron 2.\n",
        "    # Connects input 5 to output neuron 3\n",
        "    # Connects input 6 and 7 o the 4th neuron in the subsequent layer\n",
        "    # Connects nothing to the 5th neuron\n",
        "    #\n",
        "    # Writtem for Gennet framework: interpretable neural networks for phenotype prediction\n",
        "    # (https://www.biorxiv.org/content/10.1101/2020.06.19.159152v1.full)\n",
        "  Arguments:\n",
        "      mask: sparse matrix with shape (input, output) connectivity matrix,\n",
        "            True defines connection between (in_i, out_j), should be sparse (False,0) >> True\n",
        "            should be scipy sparese matrix in COO Format!\n",
        "      filters: Integer, the dimensionality of the output space\n",
        "          (i.e. the number of output filters in the convolution).\n",
        "      padding: Currently only supports `\"valid\"` (case-insensitive).\n",
        "          `\"same\"` may be supported in the future.\n",
        "      data_format: A string,\n",
        "          one of `channels_last` (default) or `channels_first`.\n",
        "          The ordering of the dimensions in the inputs.\n",
        "          `channels_last` corresponds to inputs with shape\n",
        "          `(batch, length, channels)` while `channels_first`\n",
        "          corresponds to inputs with shape\n",
        "          `(batch, channels, length)`.\n",
        "          It defaults to the `image_data_format` value found in your\n",
        "          Keras config file at `~/.keras/keras.json`.\n",
        "          If you never set it, then it will be \"channels_last\".\n",
        "      activation: Activation function to use.\n",
        "          If you don't specify anything, no activation is applied\n",
        "          (ie. \"linear\" activation: `a(x) = x`).\n",
        "      use_bias: Boolean, whether the layer uses a bias vector.\n",
        "      kernel_initializer: Initializer for the `kernel` weights matrix.\n",
        "      bias_initializer: Initializer for the bias vector.\n",
        "      kernel_regularizer: Regularizer function applied to\n",
        "          the `kernel` weights matrix.\n",
        "      bias_regularizer: Regularizer function applied to the bias vector.\n",
        "      activity_regularizer: Regularizer function applied to\n",
        "          the output of the layer (its \"activation\")..\n",
        "      kernel_constraint: Constraint function applied to the kernel matrix.\n",
        "      bias_constraint: Constraint function applied to the bias vector.\n",
        "  Input shape:\n",
        "      3D tensor with shape: `(batch_size, steps, input_dim)`\n",
        "  Output shape:\n",
        "      3D tensor with shape: `(batch_size, new_steps, filters)`\n",
        "      `steps` value might have changed due to padding or strides.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 mask,\n",
        "                 filters,\n",
        "                 padding='valid',\n",
        "                 data_format=None,\n",
        "                 activation=None,\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(LocallyDirected1D, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.padding = conv_utils.normalize_padding(padding)\n",
        "        self.data_format = conv_utils.normalize_data_format(data_format)\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "        self.input_spec = InputSpec(ndim=3)\n",
        "        self.mask = mask\n",
        "\n",
        "    @tf_utils.shape_type_conversion\n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            input_dim, input_length = input_shape[1], input_shape[2]\n",
        "        else:\n",
        "            input_dim, input_length = input_shape[2], input_shape[1]\n",
        "\n",
        "        if input_dim is None:\n",
        "            raise ValueError('Axis 2 of input should be fully-defined. '\n",
        "                             'Found shape:', input_shape)\n",
        "        self.output_length = self.mask.shape[1]\n",
        "        if self.data_format == 'channels_first':\n",
        "            self.kernel_shape = (input_dim, input_length,\n",
        "                                 self.filters, self.output_length)\n",
        "        else:\n",
        "            self.kernel_shape = (input_length, input_dim,\n",
        "                                 self.output_length, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(shape=(len(self.mask.data),),  # sum of all nonzero values in mask sum(sum(mask))\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        self.kernel_idx = sorted(get_idx(self.mask))\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=(self.output_length, self.filters),\n",
        "                initializer=self.bias_initializer,\n",
        "                name='bias',\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        if self.data_format == 'channels_first':\n",
        "            self.input_spec = InputSpec(ndim=3, axes={1: input_dim})\n",
        "        else:\n",
        "            self.input_spec = InputSpec(ndim=3, axes={-1: input_dim})\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = local_conv_matmul_sparse(inputs, self.mask, self.kernel, self.kernel_idx, self.output_length,\n",
        "                                          self.filters)\n",
        "        if self.use_bias:\n",
        "            output = Kb.bias_add(output, self.bias, data_format=self.data_format)\n",
        "\n",
        "        output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'filters':\n",
        "                self.filters,\n",
        "            'padding':\n",
        "                self.padding,\n",
        "            'data_format':\n",
        "                self.data_format,\n",
        "            'activation':\n",
        "                activations.serialize(self.activation),\n",
        "            'use_bias':\n",
        "                self.use_bias,\n",
        "            'kernel_initializer':\n",
        "                initializers.serialize(self.kernel_initializer),\n",
        "            'bias_initializer':\n",
        "                initializers.serialize(self.bias_initializer),\n",
        "            'kernel_regularizer':\n",
        "                regularizers.serialize(self.kernel_regularizer),\n",
        "            'bias_regularizer':\n",
        "                regularizers.serialize(self.bias_regularizer),\n",
        "            'activity_regularizer':\n",
        "                regularizers.serialize(self.activity_regularizer),\n",
        "            'kernel_constraint':\n",
        "                constraints.serialize(self.kernel_constraint),\n",
        "            'bias_constraint':\n",
        "                constraints.serialize(self.bias_constraint),\n",
        "        }\n",
        "        base_config = super(LocallyDirected1D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def local_conv_matmul_sparse(inputs, mask, kernel, kernel_idx, output_length, filters):\n",
        "    \"\"\"Apply N-D convolution with un-shared weights using a single matmul call.\n",
        "  Arguments:\n",
        "      inputs: (N+2)-D tensor with shape\n",
        "          `(batch_size, channels_in, d_in1, ..., d_inN)`\n",
        "          or\n",
        "          `(batch_size, d_in1, ..., d_inN, channels_in)`.\n",
        "      mask: sparse matrix COO format connectivity matrix, shape: (input layer, output layer)\n",
        "      kernel: the unshared weights for N-D convolution,\n",
        "          an (N+2)-D tensor of shape:\n",
        "          `(d_in1, ..., d_inN, channels_in, d_out2, ..., d_outN, channels_out)`\n",
        "          or\n",
        "          `(channels_in, d_in1, ..., d_inN, channels_out, d_out2, ..., d_outN)`,\n",
        "          with the ordering of channels and spatial dimensions matching\n",
        "          that of the input.\n",
        "          Each entry is the weight between a particular input and\n",
        "          output location, similarly to a fully-connected weight matrix.\n",
        "      kernel_idxs:  a list of integer tuples representing indices in a sparse\n",
        "        matrix performing the un-shared convolution as a matrix-multiply.\n",
        "      output_length = length of the output.\n",
        "      output_shape: (mask.shape[1], mask.shape[0]) is used instead.\n",
        "      filters =  standard 1\n",
        "  Returns:\n",
        "      Output (N+2)-D tensor with shape `output_shape` (Defined by the second dimension of the mask).\n",
        "  \"\"\"\n",
        "    output_shape = (mask.shape[1], mask.shape[0])\n",
        "    inputs_flat = Kb.reshape(inputs, (Kb.shape(inputs)[0], -1))\n",
        "\n",
        "#     print(\"kernel_idx\", len(kernel_idx))\n",
        "#     print(\"inputs\", K.shape(inputs_flat))\n",
        "#     print(\"kernel\", K.shape(kernel))\n",
        "\n",
        "    output_flat = Kb.sparse_ops.sparse_tensor_dense_mat_mul(\n",
        "        kernel_idx, kernel, (mask.shape[1], mask.shape[0]), inputs_flat, adjoint_b=True)\n",
        "\n",
        "    output_flat_transpose = Kb.transpose(output_flat)\n",
        "    output_reshaped = Kb.reshape(output_flat_transpose, [-1, output_length, filters])\n",
        "    return output_reshaped\n",
        "\n",
        "\n",
        "def get_idx(mask):\n",
        "    \"\"\"\"returns the transposed coordinates in tuple form:\n",
        "     [(mask.col[0], mask,row[0])...[mask.col[n], mask.row[n])]\"\"\"\n",
        "    coor_list = []\n",
        "    for i, j in zip(mask.col, mask.row):\n",
        "        coor_list.append((i, j))\n",
        "\n",
        "    return coor_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6F4IoP5T7Iq"
      },
      "source": [
        "class Autoencoder(K.models.Model):\n",
        "    def __init__(self, inputsize, latent_size, masks, latent_connection='lc', kernel_size=-1, activation='tanh'):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.inputsize = inputsize\n",
        "        self.latent_size = latent_size\n",
        "        self.latent_connection = latent_connection\n",
        "        self.kernel_size = kernel_size\n",
        "        self.latent_mask = None\n",
        "        self.latent_mask_T = None\n",
        "        self.activation = activation\n",
        "\n",
        "        self.masks = [scipy.sparse.load_npz(m) for m in masks]\n",
        "        self.masks_T = [m.transpose() for m in self.masks]\n",
        "\n",
        "        if self.latent_connection == 'lc':\n",
        "            if len(masks) == 0:\n",
        "                self.latent_mask = self.make_mask_sparse(self.inputsize, self.latent_size, kernel_size)\n",
        "            else:\n",
        "                self.latent_mask = self.make_mask_sparse(self.masks[-1].shape[1], self.latent_size, kernel_size)\n",
        "            self.latent_mask_T = self.latent_mask.transpose()\n",
        "\n",
        "        self.init_encoder()\n",
        "        self.init_decoder()\n",
        "\n",
        "        print('Model initialized successfully.')\n",
        "\n",
        "    def call(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "    def sample(self, n=1):\n",
        "        z = np.random.normal(size=(n, self.latent_size))\n",
        "        decoded = self.decoder(z)\n",
        "        return decoded\n",
        "\n",
        "    def encode(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        return encoded\n",
        "\n",
        "    def init_encoder(self):\n",
        "        self.encoder = K.Sequential()\n",
        "\n",
        "        # LocallyDirected1D layer for each mask\n",
        "        for m in self.masks:\n",
        "            size = m.shape[0]\n",
        "            self.encoder.add(K.layers.Reshape(input_shape=(size,), target_shape=(size, 1)))\n",
        "            self.encoder.add(LocallyDirected1D(mask=m, filters=1, input_shape=(size, 1)))\n",
        "            self.encoder.add(K.layers.Flatten())\n",
        "            self.encoder.add(K.layers.Activation(self.activation))\n",
        "            self.encoder.add(K.layers.BatchNormalization(center=False, scale=False))\n",
        "\n",
        "        # Code layer\n",
        "        if self.latent_connection == 'fc':\n",
        "            self.encoder.add(K.layers.Dense(units=self.latent_size))\n",
        "        elif self.latent_connection == 'lc':\n",
        "            size = self.latent_mask.shape[0]\n",
        "            self.encoder.add(K.layers.Reshape(input_shape=(size,), target_shape=(size, 1)))\n",
        "            self.encoder.add(LocallyDirected1D(mask=self.latent_mask, filters=1, input_shape=(size, 1)))\n",
        "            self.encoder.add(K.layers.Flatten())\n",
        "        else:\n",
        "            print('Invalid latent_connection argument. Valid values are \"fc\" for fully connected or \"lc\" for locally connected.')\n",
        "\n",
        "    def init_decoder(self):\n",
        "        self.decoder = K.Sequential()\n",
        "\n",
        "        # First decoder layer\n",
        "        if self.latent_connection == 'fc':\n",
        "            self.decoder.add(K.layers.Dense(units=self.masks[-1].shape[1]))\n",
        "\n",
        "        elif self.latent_connection == 'lc':\n",
        "            self.decoder.add(K.layers.Reshape(input_shape=(self.latent_size,), target_shape=(self.latent_size, 1)))\n",
        "            self.decoder.add(LocallyDirected1D(mask=self.latent_mask_T, filters=1, input_shape=(self.latent_size, 1)))\n",
        "            self.decoder.add(K.layers.Flatten())\n",
        "\n",
        "        # Decoder layer for each mask\n",
        "        for m in reversed(self.masks_T):\n",
        "            self.decoder.add(K.layers.Activation(self.activation))\n",
        "            self.decoder.add(K.layers.BatchNormalization(center=False, scale=False))\n",
        "            self.decoder.add(K.layers.Reshape(input_shape=(m.shape[0],), target_shape=(m.shape[0], 1)))\n",
        "            self.decoder.add(LocallyDirected1D(mask=m, filters=1, input_shape=(m.shape[0], 1)))\n",
        "            self.decoder.add(K.layers.Flatten())\n",
        "\n",
        "        # Adds layer with three nodes for each SNPs, which hold the probability\n",
        "        # of a 0, 1 and 2 respectively.\n",
        "        self.add_onehot_output()\n",
        "\n",
        "    def make_mask_sparse(self, inputsize, latent_size, kernel_size=None):\n",
        "        \"\"\"\n",
        "        Makes a mask so that the genes can be connected to the latent layer in a sparse manner,\n",
        "        rather than fully connected.\n",
        "        :param inputsize: Size of input layer for mask\n",
        "        :param latent_size: Size of output layer for mask\n",
        "        :param kernel_size: Number of genes connected to one latent neuron. If None: inputsize/latent_size\n",
        "        :return: returns a mask matrix\n",
        "        \"\"\"\n",
        "        \n",
        "        mask_d = np.zeros((inputsize, latent_size), np.bool)\n",
        "        if kernel_size != -1:\n",
        "            if kernel_size >= inputsize / latent_size:\n",
        "                start_neuron = np.round(np.linspace(0, inputsize-kernel_size, latent_size)).astype(int)\n",
        "                for i in range(latent_size):\n",
        "                    mask_d[start_neuron[i]:start_neuron[i]+kernel_size, i] = True\n",
        "            else:\n",
        "                print('Kernel_size should be >= inputsize / latent_size or -1, using default (-1) instead of supplied value.')\n",
        "                kernel_size = -1\n",
        "\n",
        "        if kernel_size == -1:\n",
        "            start_neuron = np.round(np.linspace(0, inputsize, latent_size+1)).astype(int)\n",
        "            for i in range(latent_size):\n",
        "                mask_d[start_neuron[i]:start_neuron[i+1], i] = True\n",
        "\n",
        "        mask = scipy.sparse.coo_matrix(mask_d)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def add_onehot_output(self):\n",
        "        \"\"\"\n",
        "        Adds onehot layer to the decoder so that categorical cross entropy loss can be used.\n",
        "        \"\"\"\n",
        "        row_indices = np.repeat(np.arange(self.inputsize), 3)\n",
        "        col_indices = np.arange(self.inputsize * 3)\n",
        "        values = np.ones(self.inputsize * 3, dtype=np.bool)\n",
        "        mask = scipy.sparse.coo_matrix((values, (row_indices, col_indices)), \n",
        "                                      shape=(self.inputsize, 3*self.inputsize), dtype=np.bool)\n",
        "        \n",
        "        self.decoder.add(K.layers.Activation(self.activation))\n",
        "        self.decoder.add(K.layers.BatchNormalization(center=False, scale=False))\n",
        "        self.decoder.add(K.layers.Reshape(input_shape=(mask.shape[0],), target_shape=(mask.shape[0], 1)))\n",
        "        self.decoder.add(LocallyDirected1D(mask=mask, filters=1, input_shape=(mask.shape[0], 1)))\n",
        "        self.decoder.add(K.layers.Flatten())\n",
        "        self.decoder.add(K.layers.Reshape(input_shape=(3*self.inputsize,), target_shape=(self.inputsize, 3)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6hZnVi9XoeF"
      },
      "source": [
        "def average_weighted_categorical_crossentropy(frequencies, dtype=K.backend.floatx()):\n",
        "    \"\"\"\n",
        "    A weighted version of keras.objectives.categorical_crossentropy.\n",
        "\n",
        "    Variables:\n",
        "        frequencies: List of length 3 cointaining the frequency of class 0, 1 and 2.\n",
        "\n",
        "    Usage:\n",
        "        weights = [0.5, 0.2, 0.3] # Class one occurs with a frequency of 0.5, class 2 0.2, class 3 0.3.\n",
        "        loss = weighted_categorical_crossentropy(frequencies)\n",
        "        model.compile(loss=loss,optimizer='adam')\n",
        "    \"\"\"\n",
        "\n",
        "    # Normalize label frequencies\n",
        "    frequencies = np.array(frequencies)\n",
        "    frequencies /= np.sum(frequencies)\n",
        "\n",
        "    # Compute and normalize weights\n",
        "    weights = 1 / frequencies\n",
        "    weights /= np.dot(frequencies, weights)\n",
        "    weights = tf.convert_to_tensor(weights, dtype=dtype)\n",
        "\n",
        "    # SparseCategoricalCrossentropy without weights\n",
        "    scce = K.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=K.losses.Reduction.NONE)\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "        loss_ = tf.cast(scce(y_true, y_pred), dtype)\n",
        "\n",
        "        # Mask to apply the correct weight to each SNP\n",
        "        mask = tf.cast(tf.math.equal(y_true, 0), dtype) * weights[0] \\\n",
        "               + tf.cast(tf.math.equal(y_true, 1), dtype) * weights[1] \\\n",
        "               + tf.cast(tf.math.equal(y_true, 2), dtype) * weights[2]\n",
        "\n",
        "        # Apply weights\n",
        "        loss_ = tf.math.multiply(loss_, mask)\n",
        "\n",
        "        loss_ = tf.math.reduce_mean(loss_)\n",
        "        return loss_\n",
        "\n",
        "    return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT27v6RRcWF0"
      },
      "source": [
        "# Function to plot confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2p1yaxDcdgU"
      },
      "source": [
        "def plot_confusion_matrix(actual_labels, predicted_labels, annotation='count'):\n",
        "    cm = confusion_matrix(actual_labels, predicted_labels).ravel()\n",
        "    cm = cm.reshape(3, 3)\n",
        "    if annotation == 'count':\n",
        "        string_format = 'd'\n",
        "    elif annotation == 'count_exp':\n",
        "        string_format = '.2e'\n",
        "    elif annotation == 'sensitivity':\n",
        "        string_format = '.3f'\n",
        "        cm = cm / cm.sum(axis=1)[:, None]\n",
        "    else:\n",
        "        print('Invalid annotation type. Default \"count\" will be used')\n",
        "        string_format = 'd'\n",
        "\n",
        "    ax = sns.heatmap(cm, annot=True, fmt=string_format, cmap='viridis')\n",
        "\n",
        "    # labels, title and ticks\n",
        "    ax.set_xlabel('PREDICTED LABELS')\n",
        "    ax.set_ylabel('ACTUAL LABELS')\n",
        "    ax.set_title('Reconstruction Confusion Matrix')\n",
        "    ax.xaxis.set_ticklabels(['0', '1', '2'])\n",
        "    ax.yaxis.set_ticklabels(['0', '1', '2'])\n",
        "\n",
        "    return cm, ax\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AdBxIcNVo1U"
      },
      "source": [
        "# Train and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "glUhdojVVruP",
        "outputId": "3982f217-6724-4205-9d4a-54c3d4964eda"
      },
      "source": [
        "################################################################################\n",
        "# PARAMETERS\n",
        "################################################################################\n",
        "\n",
        "# Parameters for simulated dataset\n",
        "genotype_size = 2000\n",
        "ld_blocks = 20\n",
        "n_haplotypes = 4\n",
        "p_mutation = 0.2\n",
        "\n",
        "train_size = 4000\n",
        "test_size = 1000\n",
        "\n",
        "# Parameters for the model\n",
        "n_genes = 100  # Number of nodes in the gene layer\n",
        "n_latent = 20  # Number of nodes in the latent layer\n",
        "\n",
        "# Parameters for training the model\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.005\n",
        "loss_weights = [(1 - p_mutation)**2,                # frequency of 0 in dataset\n",
        "                2 * p_mutation * (1-p_mutation),    # frequency of 1 in dataset\n",
        "                p_mutation**2]                      # frequency of 2 in dataset\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# PREPARE DATA AND MODEL\n",
        "################################################################################\n",
        "# Dataset\n",
        "dataset = generate_dataset(num_features=genotype_size, num_patients=train_size+test_size, \n",
        "                           ld_blocks=ld_blocks, n_haplotypes=n_haplotypes, p=p_mutation)\n",
        "train_data = dataset[:train_size]\n",
        "test_data = dataset[train_size:]\n",
        "\n",
        "# Generate mask\n",
        "mask_filename = 'Genemask_' + str(genotype_size) + '.npz'\n",
        "mask = generate_mask(genotype_size, n_genes)\n",
        "scipy.sparse.save_npz(mask_filename, mask)\n",
        "print('Saved mask file.')\n",
        "\n",
        "# Prepare model for training\n",
        "ae_model = Autoencoder(inputsize=genotype_size, latent_size=n_latent, \n",
        "                       masks=[mask_filename, ])\n",
        "loss = average_weighted_categorical_crossentropy(loss_weights)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "ae_model.compile(loss=loss, optimizer=optimizer)\n",
        "print('Model compiled successfully.')\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# TRAIN MODEL\n",
        "################################################################################\n",
        "\n",
        "history = ae_model.fit(x=train_data, y=train_data,  batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# PREDICT RECONSTRUCTION AND PLOT RESULTS\n",
        "################################################################################\n",
        "reconstruction = ae_model.predict(x=test_data)\n",
        "reconstruction = reconstruction.argmax(axis=2)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "fig.suptitle('%d LD blocks, %d haplotypes' % (ld_blocks, n_haplotypes))\n",
        "ax[0].plot(history.epoch, history.history['loss'])\n",
        "ax[0].set_title('Training loss')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_ylim((0, None))\n",
        "\n",
        "conf, ax[1] = plot_confusion_matrix(test_data.flatten(), reconstruction.flatten(), annotation='sensitivity')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating dataset with genotype size 2000 and 5000 individuals.\n",
            "Saved mask file.\n",
            "Model initialized successfully.\n",
            "Model compiled successfully.\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 6s 32ms/step - loss: 0.8008\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 4s 31ms/step - loss: 0.4895\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 4s 31ms/step - loss: 0.3819\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.3331\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 4s 31ms/step - loss: 0.3058\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 4s 31ms/step - loss: 0.2897\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.2784\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.2701\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.2650\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.2609\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}